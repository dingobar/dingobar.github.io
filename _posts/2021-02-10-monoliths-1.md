---
layout: post
title: gah monoliths
subtitle: gah legacy
cover-img: /assets/img/path.jpg
thumbnail-img: /assets/img/thumb.png
share-img: /assets/img/path.jpg
tags: [monolith, legacy, ball of mud]
---

Difficult questions ahead.

How does one apply DDD and Event Driven Architecture to the analytics plane, without creating too
many unwanted hard dependencies in the process. Some legacy systems, often monolithic, contain
terabytes of on-prem data, which have tremendous value which can be (at least partially) tapped into
through a series of ETL pipelines --> warehouse. However, the warehouse has growth pains and the
legacy systems are in a process of being re-designed and re-engineered (strangler pattern). The
warehouse is obviously a monolith itself that pretty much mirrors the legacy monolithic system 1:1 -
it reaches across every little corner of the legacy system in completely unpredictable ways. This is
a completely grid-locked situation of dependencies, in some cases even co-dependencies.

What is the preferred pattern to follow in order to loosen the coupling enough to move towards
bounded contexts and data products to replace the central on-prem data warehouse over time? Right
now I see a catch-22 situation because we cannot re-engineer the legacy system due to dependencies
to analytics solutions, and we cannot reduce dependencies to analytics solutions because we would
have to re-engineer the legacy system first. Is there any alternative to greenfielding either the
source system or the warehousing capabilities? I think I'll lose my mind before I have the answer.

Gah legacy! Gah monoliths!! Gah dependencies!!!
